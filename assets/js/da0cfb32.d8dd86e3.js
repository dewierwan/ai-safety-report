"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[753],{5139:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>c,frontMatter:()=>a,metadata:()=>i,toc:()=>h});const i=JSON.parse('{"id":"forewords","title":"Forewords","description":"Building a shared scientific understanding in a fast-moving field","source":"@site/docs/forewords.md","sourceDirName":".","slug":"/forewords","permalink":"/ai-safety-report/forewords","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Contributors","permalink":"/ai-safety-report/contributors"},"next":{"title":"About this Report","permalink":"/ai-safety-report/about"}}');var o=n(4848),r=n(8453);const a={sidebar_position:2},s="Forewords",l={},h=[{value:"Building a shared scientific understanding in a fast-moving field",id:"building-a-shared-scientific-understanding-in-a-fast-moving-field",level:2},{value:"Professor Yoshua Bengio",id:"professor-yoshua-bengio",level:3},{value:"Taking advantage of AI opportunities safely calls for global collaboration",id:"taking-advantage-of-ai-opportunities-safely-calls-for-global-collaboration",level:2},{value:"Clara Chappaz",id:"clara-chappaz",level:3},{value:"The Rt Hon Peter Kyle MP",id:"the-rt-hon-peter-kyle-mp",level:3}];function d(e){const t={em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",p:"p",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.header,{children:(0,o.jsx)(t.h1,{id:"forewords",children:"Forewords"})}),"\n",(0,o.jsx)(t.h2,{id:"building-a-shared-scientific-understanding-in-a-fast-moving-field",children:"Building a shared scientific understanding in a fast-moving field"}),"\n",(0,o.jsx)(t.h3,{id:"professor-yoshua-bengio",children:"Professor Yoshua Bengio"}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.em,{children:"Universit\xe9 de Montr\xe9al / Mila \u2013 Quebec AI Institute & Chair"})}),"\n",(0,o.jsx)(t.p,{children:"I am honoured to present the International AI Safety Report. It is the work of 96 international AI experts who collaborated in an unprecedented effort to establish an internationally shared scientific understanding of risks from advanced AI and methods for managing them."}),"\n",(0,o.jsx)(t.p,{children:"We embarked on this journey just over a year ago, shortly after the countries present at the Bletchley Park AI Safety Summit agreed to support the creation of this report. Since then, we published an Interim Report in May 2024, which was presented at the AI Seoul Summit. We are now pleased to publish the present, full report ahead of the AI Action Summit in Paris in February 2025."}),"\n",(0,o.jsx)(t.p,{children:"Since the Bletchley Summit, the capabilities of general-purpose AI, the type of AI this report focuses on, have increased further. For example, new models have shown markedly better performance at tests of programming and scientific reasoning. In addition, many companies are now investing in the development of general-purpose AI 'agents' \u2013 systems which can autonomously plan and act to achieve goals with little or no human oversight."}),"\n",(0,o.jsx)(t.p,{children:"Building on the Interim Report (May 2024), the present report reflects these new developments. In addition, the experts contributing to this report made several other changes compared to the Interim Report. For example, they worked to further improve the scientific rigour of all sections, added discussion of additional topics such as open-weight models, and restructured the report to be more relevant to policymakers, including by highlighting evidence gaps and key challenges for policymakers."}),"\n",(0,o.jsx)(t.p,{children:"I extend my profound gratitude to the team of experts who contributed to this report, including our writers, senior advisers, and the international Expert Advisory Panel. I have been impressed with their scientific excellence and expertise as well as the collaborative attitude with which they have approached this challenging project. I am also grateful to the industry and civil society organisations who reviewed the report, contributing invaluable feedback that has led this report to be more comprehensive than it otherwise would have been."}),"\n",(0,o.jsx)(t.p,{children:"My thanks also go to the UK Government for starting this process and offering outstanding operational support. It was also important for me that the UK Government agreed that the scientists writing this report should have complete independence."}),"\n",(0,o.jsx)(t.p,{children:"AI remains a fast-moving field. To keep up with this pace, policymakers and governments need to have access to the current scientific understanding on what risks advanced AI might pose. I hope that this report as well as future publications will help decision-makers ensure that people around the world can reap the benefits of AI safely."}),"\n",(0,o.jsx)(t.hr,{}),"\n",(0,o.jsx)(t.h2,{id:"taking-advantage-of-ai-opportunities-safely-calls-for-global-collaboration",children:"Taking advantage of AI opportunities safely calls for global collaboration"}),"\n",(0,o.jsx)(t.h3,{id:"clara-chappaz",children:"Clara Chappaz"}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.em,{children:"France's Minister Delegate for Artificial Intelligence"})}),"\n",(0,o.jsx)(t.h3,{id:"the-rt-hon-peter-kyle-mp",children:"The Rt Hon Peter Kyle MP"}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.em,{children:"UK Secretary of State for Science, Innovation and Technology"})}),"\n",(0,o.jsx)(t.p,{children:"Since the interim version of this report was published, the capabilities of advanced AI capabilities have continued to grow. We know that this technology, if developed and utilised safely and responsibly, offers extraordinary opportunities: to grow our economies, modernise our public services, and improve lives for our people. To seize these opportunities, it is imperative that we deepen our collective understanding of how AI can be developed safely."}),"\n",(0,o.jsx)(t.p,{children:"This landmark report is testament to the value of global cooperation in forging this shared understanding. It is the result of over 90 AI experts from different continents, sectors, and areas of expertise, coming together to offer leaders and decision-makers a global reference point and a tool to inform policy on AI safety. Our collective understanding of frontier AI systems has improved. However, this report highlights that frontier AI remains a field of active scientific inquiry, with experts continuing to disagree on its trajectory and the scope of its impact."}),"\n",(0,o.jsx)(t.p,{children:"We will maintain the momentum behind this collective effort to drive global scientific consensus. We are excited to continue this unprecedented and essential project of international collaboration."}),"\n",(0,o.jsx)(t.p,{children:"The report lays the foundation for important discussions at the AI Action Summit in France this year, which will convene international governments, leading AI companies, civil society groups and experts. This Summit, like the report, is a continuation of the milestones achieved at the Bletchley Park (November 2023) and Seoul (May 2024) summits. AI is the defining opportunity of our generation. Together, we will continue the conversation and support bold and ambitious action to collectively master the risks of AI and benefit from these new technologies for the greater good. There will be no adoption of this technology without safety: safety brings trust!"}),"\n",(0,o.jsx)(t.p,{children:"We are pleased to present this report and thank Professor Yoshua Bengio and the writing team for the significant work that went into its development. The UK and France look forward to continuing the discussion at the AI Action Summit in February."})]})}function c(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>s});var i=n(6540);const o={},r=i.createContext(o);function a(e){const t=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),i.createElement(r.Provider,{value:t},e.children)}}}]);