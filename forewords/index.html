<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-forewords" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">Forewords | International AI Safety Report 2025</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://dewierwan.github.io/ai-safety-report/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://dewierwan.github.io/ai-safety-report/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://dewierwan.github.io/ai-safety-report/forewords"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Forewords | International AI Safety Report 2025"><meta data-rh="true" name="description" content="Building a shared scientific understanding in a fast-moving field"><meta data-rh="true" property="og:description" content="Building a shared scientific understanding in a fast-moving field"><link data-rh="true" rel="icon" href="/ai-safety-report/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://dewierwan.github.io/ai-safety-report/forewords"><link data-rh="true" rel="alternate" href="https://dewierwan.github.io/ai-safety-report/forewords" hreflang="en"><link data-rh="true" rel="alternate" href="https://dewierwan.github.io/ai-safety-report/forewords" hreflang="x-default"><link rel="stylesheet" href="/ai-safety-report/assets/css/styles.15cbc4ab.css">
<script src="/ai-safety-report/assets/js/runtime~main.ed27ad42.js" defer="defer"></script>
<script src="/ai-safety-report/assets/js/main.280b6621.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ai-safety-report/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai-safety-report/"><div class="navbar__logo"><img src="/ai-safety-report/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai-safety-report/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">State of AI Safety</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ai-safety-report/contributors">Report</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/dewierwan/ai-safety-report" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-safety-report/contributors">Contributors</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/ai-safety-report/forewords">Forewords</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-safety-report/about">About this Report</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-safety-report/findings">Key Findings of the Report</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-safety-report/executive-summary/">Executive Summary</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-safety-report/introduction">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ai-safety-report/capabilities/development">1. Capabilities of General-Purpose AI</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ai-safety-report/risks/malicious-use">2. Risks</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ai-safety-report/technical-approaches/overview">3. Technical Approaches to Risk Management</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-safety-report/conclusion">Conclusion</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ai-safety-report/updates/chairs-note">Updates</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ai-safety-report/reference/acronyms">Reference</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ai-safety-report/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Forewords</span><meta itemprop="position" content="1"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Forewords</h1></header>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="building-a-shared-scientific-understanding-in-a-fast-moving-field">Building a shared scientific understanding in a fast-moving field<a href="#building-a-shared-scientific-understanding-in-a-fast-moving-field" class="hash-link" aria-label="Direct link to Building a shared scientific understanding in a fast-moving field" title="Direct link to Building a shared scientific understanding in a fast-moving field">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="professor-yoshua-bengio">Professor Yoshua Bengio<a href="#professor-yoshua-bengio" class="hash-link" aria-label="Direct link to Professor Yoshua Bengio" title="Direct link to Professor Yoshua Bengio">​</a></h3>
<p><em>Université de Montréal / Mila – Quebec AI Institute &amp; Chair</em></p>
<p>I am honoured to present the International AI Safety Report. It is the work of 96 international AI experts who collaborated in an unprecedented effort to establish an internationally shared scientific understanding of risks from advanced AI and methods for managing them.</p>
<p>We embarked on this journey just over a year ago, shortly after the countries present at the Bletchley Park AI Safety Summit agreed to support the creation of this report. Since then, we published an Interim Report in May 2024, which was presented at the AI Seoul Summit. We are now pleased to publish the present, full report ahead of the AI Action Summit in Paris in February 2025.</p>
<p>Since the Bletchley Summit, the capabilities of general-purpose AI, the type of AI this report focuses on, have increased further. For example, new models have shown markedly better performance at tests of programming and scientific reasoning. In addition, many companies are now investing in the development of general-purpose AI &#x27;agents&#x27; – systems which can autonomously plan and act to achieve goals with little or no human oversight.</p>
<p>Building on the Interim Report (May 2024), the present report reflects these new developments. In addition, the experts contributing to this report made several other changes compared to the Interim Report. For example, they worked to further improve the scientific rigour of all sections, added discussion of additional topics such as open-weight models, and restructured the report to be more relevant to policymakers, including by highlighting evidence gaps and key challenges for policymakers.</p>
<p>I extend my profound gratitude to the team of experts who contributed to this report, including our writers, senior advisers, and the international Expert Advisory Panel. I have been impressed with their scientific excellence and expertise as well as the collaborative attitude with which they have approached this challenging project. I am also grateful to the industry and civil society organisations who reviewed the report, contributing invaluable feedback that has led this report to be more comprehensive than it otherwise would have been.</p>
<p>My thanks also go to the UK Government for starting this process and offering outstanding operational support. It was also important for me that the UK Government agreed that the scientists writing this report should have complete independence.</p>
<p>AI remains a fast-moving field. To keep up with this pace, policymakers and governments need to have access to the current scientific understanding on what risks advanced AI might pose. I hope that this report as well as future publications will help decision-makers ensure that people around the world can reap the benefits of AI safely.</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="taking-advantage-of-ai-opportunities-safely-calls-for-global-collaboration">Taking advantage of AI opportunities safely calls for global collaboration<a href="#taking-advantage-of-ai-opportunities-safely-calls-for-global-collaboration" class="hash-link" aria-label="Direct link to Taking advantage of AI opportunities safely calls for global collaboration" title="Direct link to Taking advantage of AI opportunities safely calls for global collaboration">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="clara-chappaz">Clara Chappaz<a href="#clara-chappaz" class="hash-link" aria-label="Direct link to Clara Chappaz" title="Direct link to Clara Chappaz">​</a></h3>
<p><em>France&#x27;s Minister Delegate for Artificial Intelligence</em></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-rt-hon-peter-kyle-mp">The Rt Hon Peter Kyle MP<a href="#the-rt-hon-peter-kyle-mp" class="hash-link" aria-label="Direct link to The Rt Hon Peter Kyle MP" title="Direct link to The Rt Hon Peter Kyle MP">​</a></h3>
<p><em>UK Secretary of State for Science, Innovation and Technology</em></p>
<p>Since the interim version of this report was published, the capabilities of advanced AI capabilities have continued to grow. We know that this technology, if developed and utilised safely and responsibly, offers extraordinary opportunities: to grow our economies, modernise our public services, and improve lives for our people. To seize these opportunities, it is imperative that we deepen our collective understanding of how AI can be developed safely.</p>
<p>This landmark report is testament to the value of global cooperation in forging this shared understanding. It is the result of over 90 AI experts from different continents, sectors, and areas of expertise, coming together to offer leaders and decision-makers a global reference point and a tool to inform policy on AI safety. Our collective understanding of frontier AI systems has improved. However, this report highlights that frontier AI remains a field of active scientific inquiry, with experts continuing to disagree on its trajectory and the scope of its impact.</p>
<p>We will maintain the momentum behind this collective effort to drive global scientific consensus. We are excited to continue this unprecedented and essential project of international collaboration.</p>
<p>The report lays the foundation for important discussions at the AI Action Summit in France this year, which will convene international governments, leading AI companies, civil society groups and experts. This Summit, like the report, is a continuation of the milestones achieved at the Bletchley Park (November 2023) and Seoul (May 2024) summits. AI is the defining opportunity of our generation. Together, we will continue the conversation and support bold and ambitious action to collectively master the risks of AI and benefit from these new technologies for the greater good. There will be no adoption of this technology without safety: safety brings trust!</p>
<p>We are pleased to present this report and thank Professor Yoshua Bengio and the writing team for the significant work that went into its development. The UK and France look forward to continuing the discussion at the AI Action Summit in February.</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai-safety-report/contributors"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Contributors</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai-safety-report/about"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">About this Report</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#building-a-shared-scientific-understanding-in-a-fast-moving-field" class="table-of-contents__link toc-highlight">Building a shared scientific understanding in a fast-moving field</a><ul><li><a href="#professor-yoshua-bengio" class="table-of-contents__link toc-highlight">Professor Yoshua Bengio</a></li></ul></li><li><a href="#taking-advantage-of-ai-opportunities-safely-calls-for-global-collaboration" class="table-of-contents__link toc-highlight">Taking advantage of AI opportunities safely calls for global collaboration</a><ul><li><a href="#clara-chappaz" class="table-of-contents__link toc-highlight">Clara Chappaz</a></li><li><a href="#the-rt-hon-peter-kyle-mp" class="table-of-contents__link toc-highlight">The Rt Hon Peter Kyle MP</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Report</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/ai-safety-report/executive-summary/">Summary</a></li><li class="footer__item"><a class="footer__link-item" href="/ai-safety-report/findings">Key Findings</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/dewierwan/ai-safety-report" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 International AI Safety Report.</div></div></div></footer></div>
</body>
</html>